{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3480a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # 시각화를 위한 라이브러리\n",
    "\n",
    "import torch # PyTorch 라이브러리\n",
    "import torch.nn as nn # 모델 구성을 위한 라이브러리\n",
    "from torch.utils.data import DataLoader # optimizer 설정을 위한 라이브러리\n",
    "\n",
    "import torchvision # PyTorch의 컴퓨터 비전 라이브러리\n",
    "import torchvision.transforms as T # 이미지 변환을 위한 모듈\n",
    "import torchvision.utils as vutils # 이미지를 쉽게 처리하기 위한 유틸리티 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1322472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "def random_seed(seed_num):\n",
    "    torch.manual_seed(seed_num)\n",
    "    torch.cuda.manual_seed(seed_num)\n",
    "    torch.cuda.manual_seed_all(seed_num)\n",
    "    cudnn.benchmark = False\n",
    "    cudnn.deterministic = True\n",
    "    random.seed(seed_num)\n",
    "\n",
    "random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a032b8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 불러올 때, 필요한 변환(transform)을 정의합니다.\n",
    "mnist_transform = T.Compose([\n",
    "    T.ToTensor(), # 텐서 형식으로 변환\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1976bb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision 라이브러리를 사용하여 MNIST Dataset을 불러옵니다.\n",
    "download_root = '../data/MNIST_DATASET'\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(download_root, transform=mnist_transform, train=True, download=True) # train dataset 다운로드\n",
    "test_dataset = torchvision.datasets.MNIST(download_root, transform=mnist_transform, train=False, download=True) # test dataset 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a04a8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in train_dataset:\n",
    "  print(image.shape, label)  # 여기서 image의 shape은 [C, H, W]로 구성됨\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f68081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋을 학습 데이터 셋과 검증 데이터 셋으로 분리합니다.\n",
    "total_size = len(train_dataset)\n",
    "train_num, valid_num = int(total_size * 0.8), int(total_size * 0.2) # 8 : 2 = train : valid\n",
    "print(\"Train dataset 개수 : \",train_num)\n",
    "print(\"Validation dataset 개수 : \",valid_num)\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [train_num, valid_num]) # train - valid set 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39556b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# 앞서 선언한 Dataset을 인자로 주어 DataLoader를 선언합니다.\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size = batch_size, shuffle = False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87931398",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_dataloader:\n",
    "  print(images.shape, labels.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14be2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = vutils.make_grid(images, nrow=8) # 각 행마다 8개의 이미지 배치하여 격자로 구성합니다.\n",
    "\n",
    "# 학습 데이터로더로 부터 불러온 이미지를 시각화합니다\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(grid.numpy().transpose((1,2,0)))\n",
    "plt.title(\"mini batch visualization\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b49a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "  def __init__(self, hidden_dims, num_classes, dropout_ratio, apply_batchnorm, apply_dropout, apply_activation, set_super):\n",
    "    \"\"\"\n",
    "    Deep Neural Network (DNN) 클래스\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    hidden_dims : list\n",
    "        각 레이어의 뉴런 수를 정의하는 리스트\n",
    "        예: [784, 512, 256, 128] - 입력층부터 마지막 히든층까지의 차원\n",
    "        \n",
    "    num_classes : int\n",
    "        출력 클래스의 개수 (분류 문제의 클래스 수)\n",
    "        예: MNIST의 경우 10 (0~9 숫자)\n",
    "        \n",
    "    dropout_ratio : float\n",
    "        드롭아웃 비율 (0.0 ~ 1.0)\n",
    "        예: 0.5 (50%의 뉴런을 랜덤하게 비활성화)\n",
    "        \n",
    "    apply_batchnorm : bool\n",
    "        배치 정규화 적용 여부\n",
    "        True: 각 Linear 레이어 후에 BatchNorm1d 추가\n",
    "        False: 배치 정규화 생략\n",
    "        \n",
    "    apply_dropout : bool\n",
    "        드롭아웃 적용 여부\n",
    "        True: 각 레이어 후에 Dropout 추가\n",
    "        False: 드롭아웃 생략\n",
    "        \n",
    "    apply_activation : bool\n",
    "        활성화 함수 적용 여부\n",
    "        True: 각 레이어 후에 ReLU 활성화 함수 추가\n",
    "        False: 활성화 함수 생략\n",
    "        \n",
    "    set_super : bool\n",
    "        부모 클래스 초기화 여부\n",
    "        True: super().__init__() 호출 (정상적인 PyTorch 모듈로 동작)\n",
    "        False: 부모 클래스 초기화 생략 (실험적 용도)\n",
    "    \"\"\"\n",
    "    if set_super:\n",
    "      super().__init__()\n",
    "\n",
    "    self.hidden_dims = hidden_dims\n",
    "    self.layers = nn.ModuleList()\n",
    "\n",
    "    for i in range(len(self.hidden_dims) - 1):\n",
    "      self.layers.append(nn.Linear(self.hidden_dims[i], self.hidden_dims[i+1]))\n",
    "\n",
    "      if apply_batchnorm:\n",
    "        self.layers.append(nn.BatchNorm1d(self.hidden_dims[i+1]))\n",
    "\n",
    "      if apply_activation:\n",
    "        self.layers.append(nn.ReLU())\n",
    "\n",
    "      if apply_dropout:\n",
    "        self.layers.append(nn.Dropout(dropout_ratio))\n",
    "\n",
    "    self.classifier = nn.Linear(self.hidden_dims[-1], num_classes)\n",
    "    self.softmax = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\"\n",
    "    순전파 함수\n",
    "    Input:\n",
    "        x: [batch_size, 1, 28, 28] - MNIST 이미지 배치\n",
    "    \n",
    "    Output:\n",
    "        output: [batch_size, num_classes] - 각 클래스에 대한 로그 확률\n",
    "    \"\"\"\n",
    "    x = x.reshape(x.shape[0], -1)  # [batch_size, 784]\n",
    "\n",
    "    for layer in self.layers:\n",
    "      x = layer(x)\n",
    "\n",
    "    x = self.classifier(x) # [batch_size, 10]\n",
    "    output = self.softmax(x) # [batch_size, 10]\n",
    "    return output\n",
    "  \n",
    "  def weight_initialization(self, weight_init_method):\n",
    "      for m in self.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "          if weight_init_method == 'gaussian':\n",
    "            nn.init.normal_(m.weight)\n",
    "          elif weight_init_method == 'xavier':\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "          elif weight_init_method == 'kaiming':\n",
    "            nn.init.kaiming_normal_(m.weight)\n",
    "          elif weight_init_method == 'zeros':\n",
    "            nn.init.zeros_(m.weight)\n",
    "\n",
    "          nn.init.zeros_(m.bias)\n",
    "\n",
    "  def count_parameters(self):\n",
    "    return sum(p.numel() for p in self.parameters() if p.requires_grad)  # numel()은 텐서의 원소 개수를 반환하는 함수입니다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9f47c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 128\n",
    "hidden_dims = [784, hidden_dim * 4, hidden_dim * 2, hidden_dim]\n",
    "model = DNN(hidden_dims = hidden_dims, num_classes = 10, dropout_ratio = 0.2, apply_batchnorm = True, apply_dropout = True, apply_activation = True, set_super = True)\n",
    "output = model(torch.randn((32, 1, 28, 28)))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41943f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The model has {model.count_parameters():,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daf9d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def training(model, dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs):\n",
    "  model.train()  # 모델을 학습 모드로 설정\n",
    "  train_loss = 0.0\n",
    "  train_accuracy = 0\n",
    "\n",
    "  tbar = tqdm(dataloader)\n",
    "  for images, labels in tbar:\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      # 순전파\n",
    "      outputs = model(images)\n",
    "      loss = criterion(outputs, labels)\n",
    "\n",
    "      # 역전파 및 weights 업데이트\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # 손실과 정확도 계산\n",
    "      train_loss += loss.item()\n",
    "      # torch.max에서 dim 인자에 값을 추가할 경우, 해당 dimension에서 최댓값과 최댓값에 해당하는 인덱스를 반환\n",
    "      _, predicted = torch.max(outputs, 1)\n",
    "      train_accuracy += (predicted == labels).sum().item()\n",
    "\n",
    "      # tqdm의 진행바에 표시될 설명 텍스트를 설정\n",
    "      tbar.set_description(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}\")\n",
    "\n",
    "  # 에폭별 학습 결과 출력\n",
    "  train_loss = train_loss / len(dataloader)\n",
    "  train_accuracy = train_accuracy / len(train_dataset)\n",
    "\n",
    "  return model, train_loss, train_accuracy\n",
    "\n",
    "def evaluation(model, dataloader, valid_dataset, criterion, device, epoch, num_epochs):\n",
    "  model.eval()  # 모델을 평가 모드로 설정\n",
    "  valid_loss = 0.0\n",
    "  valid_accuracy = 0\n",
    "\n",
    "  with torch.no_grad(): # model의 업데이트 막기\n",
    "      tbar = tqdm(dataloader)\n",
    "      for images, labels in tbar:\n",
    "          images = images.to(device)\n",
    "          labels = labels.to(device)\n",
    "\n",
    "          # 순전파\n",
    "          outputs = model(images)\n",
    "          loss = criterion(outputs, labels)\n",
    "\n",
    "          # 손실과 정확도 계산\n",
    "          valid_loss += loss.item()\n",
    "          # torch.max에서 dim 인자에 값을 추가할 경우, 해당 dimension에서 최댓값과 최댓값에 해당하는 인덱스를 반환\n",
    "          _, predicted = torch.max(outputs, 1)\n",
    "          valid_accuracy += (predicted == labels).sum().item()\n",
    "\n",
    "          # tqdm의 진행바에 표시될 설명 텍스트를 설정\n",
    "          tbar.set_description(f\"Epoch [{epoch+1}/{num_epochs}], Valid Loss: {loss.item():.4f}\")\n",
    "\n",
    "  valid_loss = valid_loss / len(dataloader)\n",
    "  valid_accuracy = valid_accuracy / len(valid_dataset)\n",
    "\n",
    "  return model, valid_loss, valid_accuracy\n",
    "\n",
    "def training_loop(model, train_dataloader, valid_dataloader, criterion, optimizer, device, num_epochs, patience, model_name):\n",
    "    best_valid_loss = float('inf')  # 가장 좋은 validation loss를 저장\n",
    "    early_stop_counter = 0  # 카운터\n",
    "    valid_max_accuracy = -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model, train_loss, train_accuracy = training(model, train_dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs)\n",
    "        model, valid_loss, valid_accuracy = evaluation(model, valid_dataloader, valid_dataset, criterion, device, epoch, num_epochs)\n",
    "\n",
    "        if valid_accuracy > valid_max_accuracy:\n",
    "          valid_max_accuracy = valid_accuracy\n",
    "\n",
    "        # validation loss가 감소하면 모델 저장 및 카운터 리셋\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), f\"./model_{model_name}.pt\")\n",
    "            early_stop_counter = 0\n",
    "\n",
    "        # validation loss가 증가하거나 같으면 카운터 증가\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f} Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.4f}\")\n",
    "\n",
    "        # 조기 종료 카운터가 설정한 patience를 초과하면 학습 종료\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    return model, valid_max_accuracy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
