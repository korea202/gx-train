{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f70981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "\n",
    "import hydra\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "# 하이드라와 주피터 노트북은 아규먼트 관련 충돌이 발생하므로 초기화 해줌\n",
    "sys.argv = ['']\n",
    "# 환경변수 읽기\n",
    "\n",
    "load_dotenv()\n",
    "if (python_path := dotenv_values().get('PYTHONPATH')) and python_path not in sys.path: sys.path.append(python_path)\n",
    "\n",
    "from src.dataset.CvImageDatasetFastEx import get_datasets\n",
    "#from src.dataset.CvImageDataset import get_datasets\n",
    "from src.models.CustomModelEx import CustomModelEx\n",
    "from src.utils import config, utils\n",
    "\n",
    "# 시드 고정\n",
    "def random_seed(seed_num=42):\n",
    "\n",
    "    \"\"\" SEED = seed_num\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = True \"\"\"\n",
    "    \n",
    "    # seed_everything 은 위의 내용 제어 + 밑에내용\n",
    "    pl.seed_everything(seed_num)\n",
    "    #torch.backends.cudnn.deterministic = True\n",
    "    #torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# 데이터 준비 함수\n",
    "def prepare_data(default_cfg, batch_size=32, num_workers=4):\n",
    "    \n",
    "   # 데이터셋 생성\n",
    "    train_dataset, val_dataset, test_dataset = get_datasets(default_cfg)\n",
    "\n",
    "    # DataLoader 정의\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,  # 별도의 검증 데이터셋\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,  # 검증 시에는 셔플하지 않음\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def test(trainer, model, test_loader):\n",
    "\n",
    "    # 테스트\n",
    "    trainer.test(model, test_loader)\n",
    "\n",
    "    print(\"테스트 갯수=\",len(model.test_predictions))\n",
    "    \n",
    "    if len(model.test_predictions) > 0:\n",
    "        # 모든 예측값과 실제값 합치기\n",
    "        all_preds = model.test_predictions\n",
    "        \n",
    "        pred_df = pd.DataFrame(test_loader.dataset.df, columns=['ID', 'target'])\n",
    "        pred_df['target'] = all_preds\n",
    "\n",
    "        sample_submission_df = pd.read_csv(config.CV_CLS_TEST_CSV)\n",
    "        assert (sample_submission_df['ID'] == pred_df['ID']).all()\n",
    "        pred_df.to_csv(config.OUTPUTS_DIR + \"/pred.csv\", index=False)\n",
    "\n",
    "    else:\n",
    "        print(\"테스트 결과를 가져올 수 없습니다.\")\n",
    "\n",
    "@hydra.main(config_path=config.CONFIGS_DIR, config_name=\"config\", version_base=None)\n",
    "def main(cfg):\n",
    "\n",
    "    #print(cfg)\n",
    "    # cfg 에서 최상위 model 키값을 뺀다.\n",
    "    cfg = cfg.model\n",
    "\n",
    "    # 모델 초기화 전에 설정\n",
    "    torch.set_float32_matmul_precision('medium')\n",
    "    \n",
    "    # WandB Logger 초기화\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"document-image-classification\",                                                                            # 프로젝트 이름\n",
    "        name=utils.generate_experiment_name(cfg.model.model_name, cfg.optimizer.lr, cfg.data.batch_size),                   # 실험 이름 (선택사항)\n",
    "        job_type=\"train\",                                                                                                   # 작업 타입 (선택사항)\n",
    "        save_dir=config.OUTPUTS_DIR,\n",
    "        log_model=True\n",
    "\n",
    "    )\n",
    "   \n",
    "    random_seed(cfg.custom.seed_num)\n",
    "\n",
    "    model = CustomModelEx(\n",
    "        model_name= cfg.model.model_name,\n",
    "        num_classes= cfg.model.num_classes,\n",
    "        learning_rate= cfg.optimizer.lr,\n",
    "        dropout_rate= cfg.model.dropout_rate,\n",
    "        weight_decay =cfg.optimizer.weight_decay,\n",
    "        pretrained= cfg.model.pretrained,\n",
    "        cfg = cfg        )\n",
    "    # 데이터 로더 준비\n",
    "    train_loader, val_loader, test_loader = prepare_data(default_cfg=model.model.default_cfg, batch_size=cfg.data.batch_size, num_workers=cfg.data.num_workers)\n",
    "    \n",
    "\n",
    "    # 콜백을 직접 생성\n",
    "    early_stopping = hydra.utils.instantiate(cfg.callbacks.early_stopping)\n",
    "    lr_monitor = hydra.utils.instantiate(cfg.callbacks.lr_monitor)\n",
    "    model_checkpoint = hydra.utils.instantiate(cfg.callbacks.model_checkpoint)\n",
    "\n",
    "    callbacks = [early_stopping, lr_monitor, model_checkpoint]\n",
    "\n",
    "    trainer = Trainer(default_root_dir=config.OUTPUTS_DIR, max_epochs=cfg.trainer.max_epochs, accelerator=cfg.trainer.accelerator, \n",
    "                      callbacks=callbacks, logger=wandb_logger, num_sanity_val_steps=cfg.trainer.num_sanity_val_steps)\n",
    "    \n",
    "    # 훈련\n",
    "    if cfg.custom.do_checkpoint == True and os.path.exists(cfg.custom.ckpt_path):\n",
    "        trainer.fit(model, train_loader, val_loader, ckpt_path=cfg.custom.ckpt_path)\n",
    "    else:\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "    \n",
    "    # 테스트\n",
    "    if(cfg.custom.do_test == True): \n",
    "        test(trainer, model, test_loader)\n",
    "\n",
    "    # WandB 종료\n",
    "    wandb.finish()\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gx-train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
