{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f70981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "\n",
    "# 하이드라와 주피터 노트북은 아규먼트 관련 충돌이 발생하므로 초기화 해줌\n",
    "sys.argv = ['']\n",
    "# 환경변수 읽기\n",
    "\n",
    "load_dotenv()\n",
    "if (python_path := dotenv_values().get('PYTHONPATH')) and python_path not in sys.path: sys.path.append(python_path)\n",
    "\n",
    "from src.dataset.CvImageDatasetFastEx import get_datasets\n",
    "from src.models.tune_model import TuneModel\n",
    "\n",
    "\n",
    "\n",
    "# 데이터 준비 함수\n",
    "def prepare_data(model, batch_size=32, num_workers=4):\n",
    "    \n",
    "   # 데이터셋 생성\n",
    "    train_dataset, val_dataset, test_dataset = get_datasets(model)\n",
    "\n",
    "    # DataLoader 정의\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,  # 별도의 검증 데이터셋\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,  # 검증 시에는 셔플하지 않음\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback\n",
    "from ray.tune import CLIReporter\n",
    "\n",
    "\n",
    "def train_efficientnet(config):\n",
    "    \"\"\"콜백 없이 수동 리포팅하는 훈련 함수\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # GPU 사용 가능 여부 확인\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        \n",
    "        # 모델 초기화\n",
    "        model = TuneModel(\n",
    "            model_name=\"tf_efficientnet_b4\",\n",
    "            config=config\n",
    "        )\n",
    "        \n",
    "        # 데이터로더 생성\n",
    "        train_loader, val_loader, _ = prepare_data(\n",
    "            model=model, \n",
    "            batch_size=config[\"batch_size\"], \n",
    "            num_workers=2\n",
    "        )\n",
    "        \n",
    "        # 콜백 없는 간단한 Trainer 설정\n",
    "        trainer = pl.Trainer(\n",
    "            max_epochs=config[\"max_epochs\"],\n",
    "            accelerator=\"gpu\" if use_gpu else \"cpu\",\n",
    "            devices=1,\n",
    "            # callbacks=[]  # 콜백 완전 제거\n",
    "            enable_progress_bar=False,\n",
    "            logger=False,\n",
    "            precision=\"16-mixed\" if use_gpu else 32\n",
    "        )\n",
    "        \n",
    "        # 모델 훈련\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "        \n",
    "        # 검증 실행 및 결과 수집\n",
    "        val_results = trainer.validate(model, val_loader, verbose=False)\n",
    "        \n",
    "        # 메트릭 추출 및 Ray Tune에 보고\n",
    "        if val_results and len(val_results) > 0:\n",
    "            val_loss = float(val_results[0].get('val_loss', float('inf')))\n",
    "            val_acc = float(val_results[0].get('val_acc', 0.0))\n",
    "        else:\n",
    "            val_loss = float('inf')\n",
    "            val_acc = 0.0\n",
    "        \n",
    "        # Ray Tune에 수동 보고\n",
    "        tune.report(\n",
    "            val_loss=val_loss,\n",
    "            val_acc=val_acc\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ Trial 완료 - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Trial 실패: {e}\")\n",
    "        tune.report(val_loss=float('inf'), val_acc=0.0)\n",
    "\n",
    "def main():\n",
    "\n",
    "    # 모델 초기화 전에 설정\n",
    "    torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "    # 하이퍼파라미터 검색 공간 정의\n",
    "    search_space = {\n",
    "        \"learning_rate\": tune.loguniform(1e-5, 1e-2),\n",
    "        \"batch_size\": tune.choice([16, 32, 64]),\n",
    "        \"dropout_rate\": tune.uniform(0.2, 0.6),\n",
    "        \"weight_decay\": tune.loguniform(1e-6, 1e-3),\n",
    "        \"num_classes\": 17,  # 고정값\n",
    "        \"max_epochs\": 50,    # 고정값\n",
    "\n",
    "        \"scheduler_type\": tune.choice([\"plateau\", \"cosine\"]),\n",
    "        \n",
    "        # ReduceLROnPlateau 파라미터\n",
    "        \"patience\": tune.choice([3, 5, 7, 10]),\n",
    "        \"factor\": tune.uniform(0.1, 0.5),\n",
    "        \n",
    "        # CosineAnnealingLR 파라미터  \n",
    "        \"T_max\": tune.choice([20, 30, 50]),\n",
    "        \"eta_min\": tune.loguniform(1e-7, 1e-5),\n",
    "    }\n",
    "\n",
    "    pl.seed_everything(42)\n",
    "\n",
    "    # ASHA 스케줄러 설정 (조기 종료로 효율성 향상)\n",
    "    scheduler = ASHAScheduler(\n",
    "        max_t=50,           # 최대 에포크\n",
    "        grace_period=5,     # 최소 실행 에포크\n",
    "        reduction_factor=2  # 절반씩 줄여가며 선택\n",
    "    )\n",
    "    \n",
    "    # 리포터 설정 (진행상황 모니터링)\n",
    "    reporter = CLIReporter(\n",
    "        parameter_columns=[\"learning_rate\", \"batch_size\", \"dropout_rate\"],\n",
    "        metric_columns=[\"val_loss\", \"val_acc\", \"training_iteration\"]\n",
    "    )\n",
    "    \n",
    "    # Ray Tune 실행\n",
    "    analysis = tune.run(\n",
    "        train_efficientnet,\n",
    "        config=search_space,\n",
    "        metric=\"val_loss\",           # 최적화할 메트릭\n",
    "        mode=\"min\",                 # 최대화\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter,\n",
    "        num_samples=20,             # 시도할 설정 개수\n",
    "        name=\"efficientnet_b4_tune\",\n",
    "        storage_path=\"/data/ephemeral/home/python_work/git/gx-train/outputs/ray_results\"   # 결과 저장 경로\n",
    "    )\n",
    "    \n",
    "    # 최적 결과 출력\n",
    "    best_trial = analysis.get_best_trial(\"val_acc\", \"max\", \"last\")\n",
    "    print(f\"Best trial config: {best_trial.config}\")\n",
    "    print(f\"Best trial final validation accuracy: {best_trial.last_result['val_acc']}\")\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analysis = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d155967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory: 251.62 GB\n",
      "Available memory: 230.95 GB\n",
      "Used memory: 18.17 GB\n",
      "Memory percentage: 8.2%\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "def check_memory():\n",
    "    memory = psutil.virtual_memory()\n",
    "    print(f\"Total memory: {memory.total / (1024**3):.2f} GB\")\n",
    "    print(f\"Available memory: {memory.available / (1024**3):.2f} GB\")\n",
    "    print(f\"Used memory: {memory.used / (1024**3):.2f} GB\")\n",
    "    print(f\"Memory percentage: {memory.percent:.1f}%\")\n",
    "\n",
    "check_memory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gx-train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
